---
title: "Homework 6"
author: "Shaolei Ma"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
library(latex2exp)
library(gridExtra)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

Use the data cleaning procedure similar to HW5. Omit certain cities as instructed.

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = factor(
      case_when(
        disposition == "Closed without arrest" ~ "0",
        disposition == "Open/No arrest"        ~ "0",
        disposition == "Closed by arrest"      ~ "1"
    ),
    labels = c("unsolved", "solved"))
  ) |>  
  filter(
    city_state != "Tulsa, AL",
    city_state != "Dallas, TX",
    city_state != "Phoenix, AZ",
    city_state != "Kansas City, MO",
    victim_race %in% c("White", "Black")
  )
```

The resulting dataframe has `r nrow(homicide_df)` entries, on variables that include the victim name, race, age, and sex; the date the homicide was reported; and the location of the homicide. In cleaning, I created a `city_state` variable that includes both city and state, and a `resolution` variable to indicate whether the case was closed by arrest.

For the city of Baltimore, MD, use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors.

```{r}
baltimore_fit = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, data = _, family = binomial())

baltimore_fit |> 
  broom::tidy() |> 
  mutate(
    conf_low = estimate - 1.96 * std.error,
    conf_high = estimate + 1.96 * std.error,
    OR = exp(estimate),
    OR_conf_low = exp(conf_low),
    OR_conf_high = exp(conf_high)
  ) |> 
  filter(term == "victim_sexMale") |> 
  select(term, starts_with("OR"))
```

The adjusted odds ratio for solving homicides comparing male victims to female victims has an estimated value of 0.415 and a confidence interval [0.318, 0.542].

Now, run `glm` for each of the cities in the dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims.
```{r}
OR_sex_df =
  homicide_df |> 
  nest(df = - city_state) |> 
  mutate(
    models = map(df, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, data = df, family = binomial())),
    results = map(models, broom::tidy)
  ) |> 
  select(city_state, results) |> 
  unnest(results) |> 
  filter(term == "victim_sexMale") |>
  mutate(
    conf_low = estimate - 1.96 * std.error,
    conf_high = estimate + 1.96 * std.error,
    OR = exp(estimate),
    OR_conf_low = exp(conf_low),
    OR_conf_high = exp(conf_high)
  ) |> 
  select(city_state, term, starts_with("OR")) |> 
  arrange(OR)

OR_sex_df |> 
  knitr::kable()
```

Create a plot that shows the estimated ORs and CIs for each city. 
```{r}
OR_sex_df |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = OR, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = OR_conf_low, xmax = OR_conf_high)) +
  labs(title = "OR Among Cities")
```

It could be concluded that New York, NY has the lowest OR, while Albuquerque, NM has the highest OR in terms of solving homicides comparing male victims to female victims. From this plot we see that most cities have odds ratios that are smaller than 1, suggesting that crimes with male victims have smaller odds of resolution compared to crimes with female victims after adjusting for victim age and race. This disparity is strongest in New yrok. In roughly half of these cities, confidence intervals are narrow and do not contain 1, suggesting a significant difference in resolution rates by sex after adjustment for victim age and race.

# Problem 2

First, download the data.
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Focus on a linear regression with `tmax` as the response with `tmin` and `prcp` as the predictors. Use 5000 bootstrap samples to produce estimates for $\hat r^2$ and $log(\hat \beta_1*\hat \beta_2)$.

```{r}
boot_sample = function(df) {
  
  sample_frac(df, replace = T)
  
}

boot_straps =
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(weather_df))
  )

boot_results =
  boot_straps |> 
  mutate(
    models = map(strap_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy)
  ) |> 
  unnest(results) |> 
  select(strap_number, models, term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from = estimate
  )

boot_estimates =
  boot_results |> 
  mutate(
    log_beta12 = log(tmin * prcp),
    results = map(models, broom::glance)
  ) |> 
  unnest(results) |> 
  select(strap_number, r.squared, log_beta12) |> 
  pivot_longer(
    r.squared:log_beta12,
    names_to = "term",
    values_to = "estimate"
  )

p1 = 
  boot_estimates |> 
  filter(term == "r.squared") |> 
  ggplot(aes(x = estimate)) +
  geom_density() +
  labs(title = TeX("$\\hat{r^2}$ Estimate Distribution"),
       x = TeX("$\\hat{r^2}$"))

p2 = 
  boot_estimates |> 
  filter(term == "log_beta12") |> 
  ggplot(aes(x = estimate)) +
  geom_density() +
  labs(title = TeX("$log(\\hat{\\beta_1}*\\hat{\\beta_2})$ Estimate Distribution"),
       x = TeX("$log(\\hat{\\beta_1}*\\hat{\\beta_2})$"))

grid.arrange(p1, p2, nrow = 1)
```

Note: As log calculation requires the value to be larger than 0, `r boot_results |> filter(tmin * prcp <= 0) |> nrow()` observations are omitted when calculating $log(\hat \beta_1*\hat \beta_2)$.

The two distributions are both left skewed, which indicates that the variability observed in the `tmax` could be well explained by `tmin` and `prcp`, and the interaction between two independent variables should be considered. The mode for $\hat r_2$ is around 0.92, and the mode for $log(\hat \beta_1*\hat \beta_2)$ is around -5.5. The lower values may be due to outliers in the samples.

```{r echo=F}
tibble(
  r_square_low = boot_estimates |> filter(term == "r.squared") |> pull(estimate) |> quantile(0.025),
  r_square_high = boot_estimates |> filter(term == "r.squared") |> pull(estimate) |> quantile(0.975),
  log_beta_low = boot_estimates |> filter(term == "log_beta12") |> pull(estimate) |> quantile(0.025, na.rm = T),
  log_beta_high = boot_estimates |> filter(term == "log_beta12") |> pull(estimate) |> quantile(0.975, na.rm = T)
) |> 
  knitr::kable()
```

So the confidence interval for $\hat r_2$ is [0.89,0.94], and the confidence interval for $log(\hat \beta_1*\hat \beta_2)$ is [-9.13,-4.58].

# Problem 3
```{r}
birthweight_df =
  read_csv("data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate( # convert numbers to factors
    babysex = factor(
      case_match(
        babysex,
        1 ~ "male",
        2 ~ "female"
      )
    ),
    frace = factor(
      case_match(
        frace,
        1 ~ "White",
        2 ~ "Black",
        3 ~ "Asian",
        4 ~ "Puerto Rican",
        8 ~ "Other",
        9 ~ "Unknown"
      )
    ),
    mrace = factor(
      case_match(
        mrace,
        1 ~ "White",
        2 ~ "Black",
        3 ~ "Asian",
        4 ~ "Puerto Rican",
        8 ~ "Other"
      )
    ),
    malform = factor(
      case_match(
        malform,
        0 ~ "absent",
        1 ~ "present"
      )
    )
  )
```

The resulting data set has `r nrow(birthweight_df)` observations and `r ncol(birthweight_df)` variables. There is no missing data.

Now, propose a regression model for birthweight. To decide on the independent variables, I follow the conclusion of a highly cited paper published in 1987, [Determinants of low birth weight: methodological assessment and meta-analysis.](https://pubmed.ncbi.nlm.nih.gov/3322602/) It mentioned that *"In developed countries, the most important factor was cigarette smoking, followed by nutrition and pre-pregnancy weight. In developing countries the major determinants were racial origin, nutrition, low pre-pregnancy weight, short maternal stature, and malaria."* Therefore, I choose `ppwt`, `frace`, `mrace`, `mheight`, `smoken` as the independent variables.
```{r}
birthweight_fit =
  birthweight_df |> 
  lm(bwt ~ ppwt + frace + mrace + mheight + smoken, data = _)

birthweight_df |> 
  modelr::add_predictions(birthweight_fit) |> 
  modelr::add_residuals(birthweight_fit) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point()
```

From the scatterplot, it could be concluded that there is no relevance between the residuals and fitted values.

Compare the model to two others:

 * First: One using length at birth and gestational age as predictors (main effects only)

 * Second: One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
 
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) |> 
  mutate(
    mod0  = map(train, \(df) lm(bwt ~ ppwt + frace + mrace + mheight + smoken, data = df)),
    mod1  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    mod2  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead * blength + blength * babysex + bhead * babysex + bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse0 = map2_dbl(mod0, test, \(mod, df) rmse(model = mod, data = df)),
    rmse1 = map2_dbl(mod1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse2 = map2_dbl(mod2, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

According to the plots shown above, it could be concluded that both two models perform better than the proposed model, and the second model has the lowest RMSE. Therefore, we should consider interaction terms when predicting birth weight.